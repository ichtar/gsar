# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
    beats {
        port => "5044"
    }
    http { }
}


filter {
  split { field => "[sysstat][hosts][0][statistics]" }
  mutate {
    rename => {  "[sysstat][hosts][0][statistics]" => "sar_data" }
    rename => {  "[sysstat][hosts][0]" => "sar_data_root" }
  }
  if [sar_data][timestamp] {
  mutate {
    add_field  => { "timestamp" => "%{[sar_data][timestamp][date]} %{[sar_data][timestamp][time]}" }
    replace => { "[host][name]" => "%{[sar_data_root][nodename]}" }
    remove_field  => ["[sar_data][timestamp]", "[agent]", "[sar_data_root]", "[sysstat]", "[message]"]
    replace => { "[message]" => "%{[sar_data]}" }
  }
  if [sar_data][network][net-dev] {
  mutate {
    copy => { "[sar_data][network][net-dev]" => "net-dev" }
    copy => { "[sar_data][cpu-load-all]" => "cpu-load-all" }
    copy => { "[sar_data][memory]" => "memory" }
    remove_field  => ["[sar_data]"]
  }
  }

  mutate {
    remove_field  => ["[sar_data]"]
  }

  ruby {
    path => "flattenJSON.rb"
    script_params => { "field" => "net-dev" }
  }
  
  split { field => "[net-dev]" }


  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
  }
} else { drop {} }
}



output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "blargh2"
    ssl => false
#    data_stream => "true"
  }
  stdout { codec => rubydebug }
}
